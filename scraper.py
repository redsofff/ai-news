from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import json
import os
from urllib.parse import urljoin
from datetime import datetime
from newspaper import Article  # å¼•å…¥ newspaper3k åº“

# 1. è®¾ç½® Chrome é…ç½®ï¼Œå¯ç”¨æ— å¤´æ¨¡å¼
options = Options()
options.add_argument("--headless")
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")

# 2. å¯åŠ¨ Chrome æµè§ˆå™¨
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# 3. å®šä¹‰è¦æŠ“å–çš„æ–°é—»ç½‘ç«™åŠå…¶è§£æé€»è¾‘
sources = [
    {
        "name": "TechCrunch",
        "url": "https://techcrunch.com/category/artificial-intelligence/",
        "article_selector": "h3",
        "summary_selector": "p",
        "date_selector": "time",
        "link_selector": "a",
        "base_url": "https://techcrunch.com",
    },
    {
        "name": "MIT Tech Review",
        "url": "https://www.technologyreview.com/topic/artificial-intelligence/",
        "article_selector": ".story-item__title",
        "summary_selector": ".story-item__dek",
        "date_selector": ".story-item__timestamp",
        "link_selector": "a",
        "base_url": "https://www.technologyreview.com",
    },
    {
        "name": "VentureBeat AI",
        "url": "https://venturebeat.com/category/ai/",
        "article_selector": ".ArticleListing__title",
        "summary_selector": ".ArticleListing__excerpt",
        "date_selector": ".ArticleListing__timestamp",
        "link_selector": "a",
        "base_url": "https://venturebeat.com",
    },
]

latest_news = []

# 4. ä½¿ç”¨ newspaper3k æå–æ–‡ç« å†…å®¹å’Œæ‘˜è¦
def extract_summary(url):
    article = Article(url)
    article.download()
    article.parse()
    return article.text[:200]  # å–æ–‡ç« å‰200ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦

# 5. çˆ¬å–å¤šä¸ªç½‘ç«™
def scrape_website(source):
    driver.get(source["url"])
    time.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½
    soup = BeautifulSoup(driver.page_source, "html.parser")

    articles = soup.select(source["article_selector"])

    if not articles:
        print(f"âŒ {source['name']} æœªæ‰¾åˆ°æ–°é—»")
        return

    for article in articles[:10]:  # æ¯ä¸ªç«™ç‚¹æœ€å¤šæŠ“å– 10 æ¡
        link_tag = article.select_one(source["link_selector"])
        summary_tag = article.select_one(source["summary_selector"])
        date_tag = article.select_one(source["date_selector"])

        if link_tag and "href" in link_tag.attrs:
            full_url = urljoin(source["base_url"], link_tag["href"])
            title = article.text.strip()

            # ä½¿ç”¨ newspaper3k æå–æ–‡ç« æ‘˜è¦
            summary = extract_summary(full_url)

            # å¦‚æœæ²¡æœ‰æ‘˜è¦å­—æ®µï¼Œé»˜è®¤ä½¿ç”¨æ ‡é¢˜çš„å‰200ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦
            if not summary:
                summary = title[:200] + "..." if len(title) > 200 else title

            date = date_tag.text.strip() if date_tag else datetime.today().strftime("%Y-%m-%d")

            latest_news.append({
                "title": title,
                "summary": summary,
                "source": source["name"],
                "date": date,
                "url": full_url
            })
            print(f"âœ” {source['name']} - {title} - {full_url}")

# éå†æ‰€æœ‰æ–°é—»ç½‘ç«™
for source in sources:
    scrape_website(source)

# 6. åªä¿ç•™æœ€æ–° 20 æ¡æ–°é—»
latest_news = sorted(latest_news, key=lambda x: x["date"], reverse=True)[:20]

# 7. ä¿å­˜åˆ° JSON
def save_news_to_json(news):
    with open("news.json", "w", encoding="utf-8") as file:
        json.dump(news, file, indent=4, ensure_ascii=False)
    print("âœ… æ–°é—»æ•°æ®å·²ä¿å­˜åˆ° news.json")

save_news_to_json(latest_news)

# 8. Git æäº¤æ›´æ–°
def update_git_repo():
    os.system("git add news.json")
    os.system('git commit -m "æ›´æ–°æ–°é—»æ•°æ®"')
    os.system("git push origin main")
    print("ğŸš€ GitHub å·²æ›´æ–°")

update_git_repo()

# 9. å…³é—­æµè§ˆå™¨
driver.quit()
